{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.20.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\ruben\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.5.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.5.1->torchvision) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.5)\n",
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.4-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\ruben\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.0 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 10.2/43.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.0/43.0 kB 712.5 kB/s eta 0:00:00\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\ruben\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision\n",
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/stanford-cars-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.82G/1.82G [00:49<00:00, 39.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ruben\\.cache\\kagglehub\\datasets\\jessicali9530\\stanford-cars-dataset\\versions\\2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "operator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath to dataset files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\_meta_registrations.py:163\u001b[0m\n\u001b[0;32m    153\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_check(\n\u001b[0;32m    154\u001b[0m         grad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m rois\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m         ),\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mnew_empty((batch_size, channels, height, width))\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorchvision::nms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_nms\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes should be a 2d tensor, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboxes should have 4 elements in dimension 1, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\library.py:654\u001b[0m, in \u001b[0;36mregister\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_kernel\u001b[39m(\n\u001b[0;32m    621\u001b[0m     op: _op_identifier,\n\u001b[0;32m    622\u001b[0m     device_types: device_types_t,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    626\u001b[0m     lib: Optional[Library] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m ):\n\u001b[0;32m    628\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Register an implementation for a device type for this operator.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m    Some valid device_types are: \"cpu\", \"cuda\", \"xla\", \"mps\", \"ipu\", \"xpu\".\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m    This API may be used as a decorator.\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m        fn (Callable): The function to register as the implementation for\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m            the given device types.\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m        device_types (None | str | Sequence[str]): The device_types to register an impl to.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m            If None, we will register to all device types -- please only use\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m            this option if your implementation is truly device-type-agnostic.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    Examples::\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA)\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m        >>> import torch\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;124;03m        >>> from torch import Tensor\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;124;03m        >>> from torch.library import custom_op\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m        >>> import numpy as np\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;124;03m        >>>\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;124;03m        >>> # Create a custom op that works on cpu\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03m        >>> @custom_op(\"mylib::numpy_sin\", mutates_args=(), device_types=\"cpu\")\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m        >>> def numpy_sin(x: Tensor) -> Tensor:\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;124;03m        >>>     x_np = x.numpy()\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03m        >>>     y_np = np.sin(x_np)\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;124;03m        >>>     return torch.from_numpy(y_np)\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m        >>>\u001b[39;00m\n\u001b[1;32m--> 654\u001b[0m \u001b[38;5;124;03m        >>> # Add implementations for the cuda device\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;124;03m        >>> @torch.library.register_kernel(\"mylib::numpy_sin\", \"cuda\")\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;124;03m        >>> def _(x):\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;124;03m        >>>     x_np = x.cpu().numpy()\u001b[39;00m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03m        >>>     y_np = np.sin(x_np)\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;124;03m        >>>     return torch.from_numpy(y_np).to(device=x.device)\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;124;03m        >>>\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;124;03m        >>> x_cpu = torch.randn(3)\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;124;03m        >>> x_cuda = x_cpu.cuda()\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;124;03m        >>> assert torch.allclose(numpy_sin(x_cpu), x_cpu.sin())\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m        >>> assert torch.allclose(numpy_sin(x_cuda), x_cuda.sin())\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    669\u001b[0m         op, (\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39m_ops\u001b[38;5;241m.\u001b[39mOpOverload, torch\u001b[38;5;241m.\u001b[39m_library\u001b[38;5;241m.\u001b[39mcustom_ops\u001b[38;5;241m.\u001b[39mCustomOpDef)\n\u001b[0;32m    670\u001b[0m     ):\n\u001b[0;32m    671\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_kernel(op): got unexpected type for op: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mtype(op)}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\library.py:154\u001b[0m, in \u001b[0;36m_register_fake\u001b[1;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_preexisting_packet:\n\u001b[0;32m    153\u001b[0m     ns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mns)\n\u001b[1;32m--> 154\u001b[0m     packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ns, packet_name)\n\u001b[0;32m    155\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_ops\u001b[38;5;241m.\u001b[39m_refresh_packet(packet)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_defs\u001b[38;5;241m.\u001b[39madd(qualname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_library\\abstract_impl.py:31\u001b[0m, in \u001b[0;36mAbstractImplHolder.register\u001b[1;34m(self, func, source)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an fake impl registered at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m     )\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_has_kernel_for_dispatch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqualname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_has_kernel_for_dispatch_key(\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqualname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompositeImplicitAutograd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m ):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"jessicali9530/stanford-cars-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    \"/root/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "def show_images(data_loader, num_samples=20, cols=4):\n",
    "    \"\"\" Plots some samples from the dataset \"\"\"\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i, (images, ) in enumerate(data_loader):\n",
    "        if i == num_samples // 4:  # as we are using batch_size=4\n",
    "            break\n",
    "        for j in range(4):  # each batch contains 4 images\n",
    "            plt.subplot(num_samples // cols, cols, i * 4 + j + 1)\n",
    "            plt.imshow(images[j].permute(1, 2, 0))  # Convert tensor to HWC format\n",
    "            plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "show_images(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def linear_beta_schedule(timesteps, start=0.0001, end=0.02):\n",
    "    return torch.linspace(start, end, timesteps)\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    \"\"\" \n",
    "    Returns a specific index t of a passed list of values vals\n",
    "    while considering the batch dimension.\n",
    "    \"\"\"\n",
    "    batch_size = t.shape[0]\n",
    "    out = vals.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n",
    "    \"\"\" \n",
    "    Takes an image and a timestep as input and \n",
    "    returns the noisy version of it\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_0)\n",
    "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
    "    )\n",
    "    # mean + variance\n",
    "    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n",
    "    + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
    "\n",
    "\n",
    "# Define beta schedule\n",
    "T = 300\n",
    "betas = linear_beta_schedule(timesteps=T)\n",
    "\n",
    "# Pre-calculate different terms for closed form\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def load_transformed_dataset():\n",
    "    data_transforms = [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(), # Scales data into [0,1] \n",
    "        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    ]\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "\n",
    "    train = torchvision.datasets.StanfordCars(root=\".\", download=True, \n",
    "                                         transform=data_transform)\n",
    "\n",
    "    test = torchvision.datasets.StanfordCars(root=\".\", download=True, \n",
    "                                         transform=data_transform, split='test')\n",
    "    return torch.utils.data.ConcatDataset([train, test])\n",
    "def show_tensor_image(image):\n",
    "    reverse_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "        transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "        transforms.Lambda(lambda t: t * 255.),\n",
    "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "        transforms.ToPILImage(),\n",
    "    ])\n",
    "\n",
    "    # Take first image of batch\n",
    "    if len(image.shape) == 4:\n",
    "        image = image[0, :, :, :] \n",
    "    plt.imshow(reverse_transforms(image))\n",
    "\n",
    "data = load_transformed_dataset()\n",
    "dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate forward diffusion\n",
    "image = next(iter(dataloader))[0]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis('off')\n",
    "num_images = 10\n",
    "stepsize = int(T/num_images)\n",
    "\n",
    "for idx in range(0, T, stepsize):\n",
    "    t = torch.Tensor([idx]).type(torch.int64)\n",
    "    plt.subplot(1, num_images+1, int(idx/stepsize) + 1)\n",
    "    img, noise = forward_diffusion_sample(image, t)\n",
    "    show_tensor_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, x_0, t):\n",
    "    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n",
    "    noise_pred = model(x_noisy, t)\n",
    "    return F.l1_loss(noise, noise_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
